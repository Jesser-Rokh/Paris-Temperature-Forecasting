{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc624bf",
   "metadata": {},
   "source": [
    "I - Analyses préliminaires : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d352135",
   "metadata": {},
   "source": [
    "=== 1. Import des librairies ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6156ad85",
   "metadata": {},
   "source": [
    "=== 2. Lecture du fichier ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a30cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/hourly_data.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e1c25",
   "metadata": {},
   "source": [
    "=== 3. Aperçu général ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9423cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de lignes :\", df.shape[0])\n",
    "print(\"Nombre de colonnes :\", df.shape[1])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dff633",
   "metadata": {},
   "source": [
    "=== 4. Infos générales ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574dea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Informations générales sur le dataset ===\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d208d",
   "metadata": {},
   "source": [
    "=== 5. Vérification des valeurs manquantes ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Pourcentage de valeurs manquantes par colonne ===\")\n",
    "missing = df.isna().mean() * 100\n",
    "display(missing[missing > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc07e9",
   "metadata": {},
   "source": [
    "--> 2 variables ayant des valeurs manquantes au taux de moins de 2% (taux faible)\n",
    "--> 3 options : \n",
    "        - supprimer les lignes ayant des valeurs manquantes et suivre le processus\n",
    "        - imputer les valeurs manquantes`: interpolation temporelle, préférable pour la modélisation \n",
    "        - voir l'importance de ces deux variables dans la modélisation et voir si c'est intéressant de les supprimer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da488c79",
   "metadata": {},
   "source": [
    "=== 6. Localisation des valeurs manquantes et interprétations ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9670bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = df[df['boundary_layer_height'].isna() | df['total_column_integrated_water_vapour'].isna()]\n",
    "print(\"Nombre de lignes concernées :\", len(missing_rows))\n",
    "display(missing_rows.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ae821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les indices des lignes où il y a des valeurs manquantes\n",
    "missing_rows = df[df['boundary_layer_height'].isna() | df['total_column_integrated_water_vapour'].isna()]\n",
    "\n",
    "print(f\"➡️ Nombre total de lignes avec des valeurs manquantes : {len(missing_rows)}\")\n",
    "print(\"\\nExemples de lignes concernées :\")\n",
    "display(missing_rows.head())\n",
    "\n",
    "# Vérifions la période concernée (utile car les données sont temporelles)\n",
    "print(\"\\n=== Périodes où les valeurs manquent ===\")\n",
    "missing_periods = missing_rows[['time']].sort_values(by='time')\n",
    "display(missing_periods.head(10))\n",
    "display(missing_periods.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6f29c",
   "metadata": {},
   "source": [
    "# vérifier si les valeurs manquantes sont regroupées dans le temps :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_times = df.loc[\n",
    "    df['boundary_layer_height'].isna() | df['total_column_integrated_water_vapour'].isna(),\n",
    "    'time'\n",
    "]\n",
    "print(\"Période minimale :\", missing_times.min())\n",
    "print(\"Période maximale :\", missing_times.max())\n",
    "\n",
    "# Pour voir si elles sont continues ou dispersées\n",
    "missing_times = pd.to_datetime(missing_times)\n",
    "missing_gaps = missing_times.diff().dt.total_seconds().dropna()\n",
    "\n",
    "print(\"\\nDistribution des écarts temporels entre valeurs manquantes :\")\n",
    "display(missing_gaps.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b1f05",
   "metadata": {},
   "source": [
    "--> mean=min=max=3600s=1h donc toutes les différences entre deux valeurs manquantes consécutives sont exactement 1 heure\n",
    "\n",
    "--> Vérification manuelle : Janvier : 31 jours → 31 × 24 = 744 h / Février 2024 (année bissextile) : 29 × 24 = 696 h / Mars : 31 × 24 = 744 h / Avril : 30 × 24 = 720 h / Mai : 31 × 24 = 744 h / Juin : 30 × 24 = 720 h et on commence le 1er janvier à 01:00 donc 743 + 696 + 744 + 720 + 744 + 720 = 4367 gaps\n",
    "\n",
    "--> Les écarts temporels entre les lignes manquantes sont exactement d’une heure, ce qui signifie que les données manquantes suivent la même fréquence horaire que le dataset \n",
    "\n",
    "--> Ces valeurs manquantes sont donc réparties régulièrement dans le temps mais représentent une faible proportion des observations (≈1.93%)\n",
    "\n",
    "--> Pour conserver la cohérence temporelle et ne pas supprimer de données, il est préférable d’appliquer une interpolation temporelle. Cela permettra au modèle de prédiction de garder un signal complet et régulier sans introduire de biais\n",
    "\n",
    "--> Par la suite, si ces colonnes ne s’avèrent pas pertinentes pour la modélisation, elles pourront être supprimées ou ignorées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45762336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Statistiques descriptives ===\n",
    "print(\"\\n=== Statistiques descriptives ===\")\n",
    "display(df.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba11ad",
   "metadata": {},
   "source": [
    "# === 7. Interpolation temporelle ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ab12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de la colonne 'time' en datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Mise en index temporel pour faciliter l'interpolation\n",
    "df = df.set_index('time')\n",
    "\n",
    "# Vérification du nombre de valeurs manquantes avant interpolation\n",
    "print(\"Valeurs manquantes avant interpolation :\")\n",
    "print(df[['boundary_layer_height', 'total_column_integrated_water_vapour']].isna().sum())\n",
    "\n",
    "# Interpolation temporelle pour remplir les valeurs manquantes\n",
    "df['boundary_layer_height'] = df['boundary_layer_height'].interpolate(method='time')\n",
    "df['total_column_integrated_water_vapour'] = df['total_column_integrated_water_vapour'].interpolate(method='time')\n",
    "\n",
    "# Vérification après interpolation\n",
    "print(\"\\n Valeurs manquantes après interpolation :\")\n",
    "print(df[['boundary_layer_height', 'total_column_integrated_water_vapour']].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab6995",
   "metadata": {},
   "source": [
    "II - Exploration des variables : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47709592",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de lignes :\", df.shape[0])\n",
    "print(\"Nombre de colonnes :\", df.shape[1])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0d5ac",
   "metadata": {},
   "source": [
    " === 1. Statistiques descriptives générales ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe().T)\n",
    "\n",
    "# Vérifier les colonnes avec peu de variance ou valeurs uniques\n",
    "low_var_cols = [c for c in df.columns if df[c].nunique() <= 1]\n",
    "print(\"Colonnes avec peu de variance :\", low_var_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0d427",
   "metadata": {},
   "source": [
    "--> Temperature : moyenne ≈ 12°C, min -10.5°C, max 40.9°C → bonne plage de températures\n",
    "--> precipitation et rain ont une majorité de 0 → rare mais avec quelques fortes valeurs (max 15.4 mm) \n",
    "--> snowfall et snow_depth sont très faibles → peu d’occurrences de neige\n",
    "--> Vent : wind_speed_10m et wind_speed_100m ont des moyennes modérées mais des valeurs max importantes (52 et 79 m/s)\n",
    "--> Couverture nuageuse : cloud_cover, cloud_cover_low/mid/high montrent une grande variabilité (écarts-types élevés)\n",
    "--> Sol : températures et humidité du sol sont stables avec une légère diminution de la variabilité en profondeur\n",
    "--> Paramètres extrêmes : boundary_layer_height et sunshine_duration ont des valeurs très dispersées (écarts-types très grands)\n",
    "--> boundary_layer_height et total_column_integrated_water_vapour semblent avoir des valeurs raisonnables et sans NaN (après interpolation)\n",
    "--> Toutes les colonnes ont beaucoup de valeurs différentes → aucune colonne avec peu de variance (low_var_cols = []). Ça veut dire que toutes les colonnes apportent un peu d’information, on ne va pas supprimer de colonnes juste pour manque de variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14650eaf",
   "metadata": {},
   "source": [
    "Identifier les types de variables : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f8924",
   "metadata": {},
   "source": [
    "Pour les variables catégorielles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9858359",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in df.columns if df[c].dtype=='int64' and df[c].nunique() < 50 or df[c].dtype=='object']\n",
    "for c in cat_cols:\n",
    "    print(f\"\\nColonne : {c} --> {df[c].nunique()} valeurs uniques\")\n",
    "    print(df[c].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c8eb6b",
   "metadata": {},
   "source": [
    "Pour les variables numériques continues : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [c for c in df.select_dtypes(include=['float64', 'int64']).columns \n",
    "            if c not in cat_cols + ['temperature_2m']]  # exclure cat_cols et la cible\n",
    "\n",
    "print(f\"Nombre de variables numériques continues : {len(num_cols)}\")\n",
    "print(\"Variables :\", num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df4065",
   "metadata": {},
   "source": [
    "=== Statistiques descriptives détaillées ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df632c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives = pd.DataFrame(index=num_cols)\n",
    "\n",
    "descriptives['count'] = df[num_cols].count()\n",
    "descriptives['mean'] = df[num_cols].mean()\n",
    "descriptives['std'] = df[num_cols].std()\n",
    "descriptives['min'] = df[num_cols].min()\n",
    "descriptives['25%'] = df[num_cols].quantile(0.25)\n",
    "descriptives['50%'] = df[num_cols].median()\n",
    "descriptives['75%'] = df[num_cols].quantile(0.75)\n",
    "descriptives['max'] = df[num_cols].max()\n",
    "descriptives['skew'] = df[num_cols].apply(lambda x: skew(x))\n",
    "descriptives['kurtosis'] = df[num_cols].apply(lambda x: kurtosis(x))\n",
    "descriptives['zeros (%)'] = df[num_cols].apply(lambda x: (x==0).sum()/len(x)*100)\n",
    "\n",
    "display(descriptives)\n",
    "\n",
    "# ===  Distribution des variables ===\n",
    "for c in num_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[c], bins=50, kde=True)\n",
    "    plt.title(f\"Distribution de {c}\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd2932",
   "metadata": {},
   "source": [
    "--> Humidité relative (relative_humidity_2m) : Moyenne : 76.6 %, assez élevée → il fait globalement humide / Skew négatif (-0.75) → la distribution est légèrement concentrée vers les valeurs élevées (80-100 %).\n",
    "--> Températures (apparent_temperature, dew_point_2m) : Apparent temperature moyenne : ~10°C, avec des valeurs allant jusqu’à 41.7°C (valeurs extrêmes possibles en été ou journée chaude) / Skew légèrement positif pour apparent temp → quelques valeurs très chaudes.\n",
    "--> Précipitations, pluie, neige : Très nombreuses valeurs nulles : 85 % pour la pluie, 99 % pour la neige / Distribution très asymétrique (skew très élevé) → la plupart des jours sont secs / Cela signifie que ces variables sont très sparsely populated, et qu’une transformation ou agrégation pourrait être nécessaire.\n",
    "--> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189b962",
   "metadata": {},
   "source": [
    "Distributions particulières : \n",
    "- relative_humidity_2m : Moyenne : 76.6 %, assez élevée → il fait globalement humide / Fortement Asymétrique (vers la gauche), biaisée vers les valeurs élevées --> Standardisation/Normalisation ou une transformation légère (comme une mise à l'échelle puissance) pourrait aider à gérer l'asymétrie\n",
    "- wind_speed_10m : Très fortement asymétrique vers la droite --> Transformation logarithmique (log) ou racine carrée pour réduire l'asymétrie et traiter les valeurs extrêmes. Ensuite, Standardisation.\n",
    "- wind_speed_100m : Similaire à wind_speed_10m, mais le mode est plus élevé --> Transformation logarithmique (log) ou racine carrée pour réduire l'asymétrie. Ensuite, Standardisation.\n",
    "- rain et precipitation : Ces distributions sont dominées par un pic massif à zéro --> Créer une variable binaire \"Pluie/Non-Pluie\" ou \"Précipitations/Non-Précipitations\" OU Transformation : Appliquer un log(x+ϵ) sur les valeurs non nulles pour réduire l'asymétrie des rares événements OU Mise à l'échelle : Normalisation ou mise à l'échelle des valeurs.\n",
    "- snowfall et snow_depth : Extrêmement Asymétrique (Pics à zéro) avec presque toutes les valeurs à zéro --> Variable binaire : Créer une variable binaire \"Neige/Non-Neige\" pour snowfall et/ou snow_depth > 0. OU Simplification : Étant donné la rareté des valeurs non nulles, ces variables pourraient être moins informatives pour la prédiction de la température future (sauf si la neige est un prédicteur de températures basses)\n",
    "- wind_speed_10m et wind_speed_100m : Fortement Asymétrique (vers la droite) --> Transformation Logarithmique (log(x+1)) ou Racine Carrée pour réduire l'asymétrie et la variance des valeurs extrêmes. Puis, Standardisation.\n",
    "- wind_gusts_10m : Fortement Asymétrique (vers la droite), très similaire aux vitesses de vent moyennes, mais avec des valeurs maximales plus élevées --> Transformation Logarithmique (log(x+1)) pour gérer la forte asymétrie et les valeurs extrêmes. Puis, Standardisation.\n",
    "- wind_direction_10m et wind_direction_100m : Distribution bimodale claire, avec des pics autour de 30-40° (Nord-Est ou Nord) et 220-240° (Sud-Ouest) --> Encodage Cyclique (Sinus/Cosinus). Utiliser la variable brute comme numérique est incorrect (359° est très proche de 0°, mais leur différence numérique est 359), Transformer en sin(θ) et cos(θ) \n",
    "- vapour_pressure_deficit : Pic massif près de zéro, avec une longue traîne --> Transformation Logarithmique (log(x+ϵ)) ou Racine Carrée pour gérer l'asymétrie et les zéros. Puis, Standardisation.\n",
    "- et0_fao_evapotranspiration : Pic massif à zéro ou très proche, avec une longue traîne --> Créer une variable binaire \"ET > 0\"\n",
    "- sunshine_duration : Bimodale Extrême / Pics aux extrémités --> Variable Binaire \n",
    "- cloud_cover, cloud_cover_low, mid et high : Bimodales Extrêmes --> Normalisation Min-Max (si ce n'est pas déjà fait : 0−100%). Pour certains modèles, une transformation non linéaire peut aider, mais les arbres de décision/boosting gèrent bien cette forme. Une stratégie de segmentation (binaire/catégorielle) pourrait être envisagée (ex: Dégagé <10%, Partiel 10%−90%, Couvert >90%).\n",
    "- vapour_pressure_deficit : Pic massif près de zéro, longue traîne --> Transformation Logarithmique (log(x+ϵ)) et Standardisation. \n",
    "- total_column_integrated_water_vapour : Asymétrique (vers la droite) --> Standardisation/Normalisation. Une légère transformation (log ou racine carrée) pourrait être envisagée pour adoucir la queue, mais la standardisation pourrait être suffisante.\n",
    "- boundary_layer_height : Fortement Asymétrique (vers la droite) --> Transformation Logarithmique (log(x+1)) pour gérer la forte asymétrie et la longue traîne, puis Standardisation !! \n",
    "- soil_moisture_0_to_7cm : Distribution fortement biaisée vers les valeurs élevées --> Standardisation/Normalisation. Aucune transformation Logarithmique n'est nécessaire car elle est biaisée vers la gauche et non vers la droite\n",
    "- soil_moisture_7_to_28cm, soil_moisture_28_to_100cm et soil_moisture_100_to_255cm : Les distributions sont moins biaisées que la couche superficielle et montrent plusieurs pics. L'humidité du sol en profondeur est plus stable (moins influencée par les événements immédiats), représentant l'état hydrique à long terme. --> Une simple mise à l'échelle est la meilleure approche, en laissant le modèle gérer la multimodalité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5be8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Boxplots pour détecter les valeurs aberrantes ===\n",
    "for c in num_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=df[c])\n",
    "    plt.title(f\"Boxplot de {c}\")\n",
    "    plt.show()\n",
    "\n",
    "# === 5. Corrélation avec la cible temperature_2m ===\n",
    "corr_matrix = df[num_cols + ['temperature_2m']].corr()\n",
    "corr_with_target = corr_matrix['temperature_2m'].sort_values(ascending=False)\n",
    "print(\"\\n=== Corrélation des variables numériques continues avec temperature_2m ===\")\n",
    "display(corr_with_target)\n",
    "\n",
    "# Visualisation des corrélations via heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
